{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "35I0Rq_ALBn1"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import fashion_mnist\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "95tMwn2GLBn-"
   },
   "outputs": [],
   "source": [
    "def sigmoid(a):\n",
    "    s = 1/(1+np.exp(-a))\n",
    "    return s\n",
    "\n",
    "def derivative_sigmoid(a):\n",
    "    ds = sigmoid(a) *(1-sigmoid (a))\n",
    "    return ds\n",
    "\n",
    "def tanh(a):\n",
    "    t=(np.exp(a)-np.exp(-a))/(np.exp(a)+np.exp(-a))\n",
    "    return t\n",
    "\n",
    "def derivative_tanh(a):\n",
    "    dt=1-tanh(a)**2\n",
    "    return dt\n",
    "\n",
    "\n",
    "def softmax(a):\n",
    "    return np.exp(a) / np.sum(np.exp(a), axis=0) #expA (axis=0, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "jPo8y7emLBn_"
   },
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yaktHRmbLBn_",
    "outputId": "d34bec94-2a04-4235-81ff-4f96c7c87ead"
   },
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(x_train_orig, y_train_orig), (x_test_orig, y_test_orig) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "Pgc8UpKtLBn_"
   },
   "outputs": [],
   "source": [
    "def initialize_parameters(layer_dimensions):\n",
    "\n",
    "    #np.random.seed(0)\n",
    "    parameters = {}\n",
    "    L = len(layer_dimensions)            # number of layers in the network\n",
    "\n",
    "    for k in range(1, L):\n",
    "        \n",
    "        parameters['w' + str(k)] = np.random.randn(layer_dimensions[k], layer_dimensions[k-1]) \n",
    "        parameters['b' + str(k)] = np.zeros((layer_dimensions[k], 1))\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_update(layer_dimensions):\n",
    "\n",
    "    #np.random.seed(0)\n",
    "    update = {}\n",
    "    L = len(layer_dimensions)            # number of layers in the network\n",
    "\n",
    "    for k in range(1, L):\n",
    "        \n",
    "        update['update_w' + str(k)] = np.zeros((layer_dimensions[k], layer_dimensions[k-1])) \n",
    "        update['update_b' + str(k)] = np.zeros((layer_dimensions[k], 1))\n",
    "        \n",
    "    return update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "44uvQtw7LBoA"
   },
   "outputs": [],
   "source": [
    "def agrregation_forward(h, w, b):\n",
    "    \n",
    "    a = np.dot(w, h) + b\n",
    "    temp = (h,w,b)\n",
    "    \n",
    "    return a ,temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "ynL63aRULBoA"
   },
   "outputs": [],
   "source": [
    "def activation_forward(h_prev, w, b, activation):\n",
    "        \n",
    "    \n",
    "    if activation == \"sigmoid\":\n",
    "\n",
    "        a, linear_temp = agrregation_forward(h_prev, w, b)\n",
    "        h = sigmoid(a)\n",
    "    \n",
    "    elif activation == \"tanh\":\n",
    "        a, linear_temp = agrregation_forward(h_prev, w, b)\n",
    "        h = tanh(a)\n",
    "        \n",
    "    elif activation == \"softmax\":\n",
    "        a, linear_temp = agrregation_forward(h_prev, w, b)\n",
    "        h = softmax(a)\n",
    "    \n",
    "    \n",
    "    temp = (linear_temp, a)\n",
    "\n",
    "    return h, temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "d7MK5JmxLBoB"
   },
   "outputs": [],
   "source": [
    "def forward_pass(x, parameters):\n",
    "\n",
    "    temps = []\n",
    "    h = x\n",
    "    L = len(parameters) // 2                  # number of layers in the neural network\n",
    "    \n",
    "    for k in range(L-1):\n",
    "        l = k+1\n",
    "        h_prev = h \n",
    "        h,temp = activation_forward(h_prev, parameters['w'+str(l)], parameters['b'+str(l)], activation=\"sigmoid\")\n",
    "        temps.append(temp)\n",
    "    \n",
    "    \n",
    "    hL,temp1 = activation_forward(h, parameters['w'+str(L)], parameters['b'+str(L)], activation=\"softmax\")\n",
    "    temps.append(temp1)\n",
    "    \n",
    "            \n",
    "    return hL, temps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "OX6qxo5yLBoB"
   },
   "outputs": [],
   "source": [
    "def cost_function(yhat, y):   \n",
    "    m = y.shape[1] # no. of examples\n",
    "  \n",
    "    product_sum = np.sum((y *np.log(yhat)), axis = 0)\n",
    "    cost = -1/m*np.sum(product_sum)\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "4sEmnKQzLBoB"
   },
   "outputs": [],
   "source": [
    "def agrregation_backward(dL_da, temp):\n",
    "    \n",
    "    h_prev, w, b = temp \n",
    "    m = h_prev.shape[1]\n",
    "    dL_dh_prev = np.dot(w.T, dL_da)\n",
    "    \n",
    "    dL_dw = 1/m*np.dot(dL_da, h_prev.T)\n",
    "    dL_db = 1/m*np.sum(dL_da, axis=1, keepdims=True)\n",
    "     \n",
    "\n",
    "    return dL_dh_prev, dL_dw, dL_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "k5_8wzplLBoC"
   },
   "outputs": [],
   "source": [
    "def activation_backward(dL_dh, temp, activation):\n",
    "\n",
    "    linear_temp, a = temp\n",
    "    \n",
    "    if activation == \"sigmoid\":\n",
    "        ds = derivative_sigmoid(a)\n",
    "        dL_da = dL_dh * ds\n",
    "       \n",
    "        dL_dh_prev, dL_dw, dL_db = agrregation_backward(dL_da, linear_temp)    \n",
    "        \n",
    "    elif activation == \"tanh\":\n",
    "        dt = derivative_tanh(a)\n",
    "        dL_da = dL_dh * dt\n",
    "\n",
    "        dL_dh_prev, dL_dw, dL_db = agrregation_backward(dL_da, linear_temp)    \n",
    "    \n",
    "    return dL_dh_prev, dL_dw, dL_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "Izs4-_QvLBoC"
   },
   "outputs": [],
   "source": [
    "def backward_pass(yhat, y, temps):\n",
    "    \n",
    "    grads = {}\n",
    "    L = len(temps) # the number of layers\n",
    "    m = y.shape[1]\n",
    "\n",
    "# el = one hot vector\n",
    "    el = y\n",
    "    dL_dyhat = -(1/yhat)*el\n",
    "    dL_daL  = -(el - yhat)\n",
    "    current_temp = temps[L-1]\n",
    "    linear_tempL,aL = current_temp\n",
    "    \n",
    "    hL_prev, wL, bL = linear_tempL\n",
    "    m = hL_prev.shape[1]\n",
    "\n",
    "    dL_dhL_prev = np.dot(wL.T, dL_daL)\n",
    "    \n",
    "    dL_dwL = 1/m*np.dot(dL_daL, hL_prev.T)\n",
    "    dL_dbL = 1/m*np.sum(dL_daL, axis=1, keepdims=True)\n",
    "\n",
    "    grads[\"dL_dh\" + str(L-1)] = dL_dhL_prev\n",
    "    grads[\"dL_dw\" + str(L)]      = dL_dwL\n",
    "    grads[\"dL_db\" + str(L)] = dL_dbL\n",
    "    \n",
    "    # Loop from l=L-2 to l=0\n",
    "    for l in reversed(range(L-1)):\n",
    "        #print(l)\n",
    "        current_temp = temps[l]\n",
    "        dL_dh_prev, dL_dw, dL_db = activation_backward(grads[\"dL_dh\" + str(l+1)], current_temp, \"sigmoid\")\n",
    "        grads[\"dL_dh\" + str(l)] = dL_dh_prev\n",
    "        grads[\"dL_dw\" + str(l + 1)] = dL_dw\n",
    "        grads[\"dL_db\" + str(l + 1)] = dL_db\n",
    "\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "SzwkIK5CLBoD"
   },
   "outputs": [],
   "source": [
    "def parameter_update_vanilla(parameters, grads,learning_rate):\n",
    "    \n",
    "    L = len(parameters) // 2 # number of layers in the neural network\n",
    "\n",
    "    for l in range(L):\n",
    "        \n",
    "        parameters[\"w\" + str(l+1)] = parameters[\"w\" + str(l+1)]- learning_rate*grads[\"dL_dw\" + str(l + 1)]\n",
    "        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)]- learning_rate*grads[\"dL_db\" + str(l + 1)]\n",
    "\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameter_update_momentum(parameters, grads, update, learning_rate ,gamma):\n",
    "    \n",
    "    L = len(parameters) // 2 # number of layers in the neural network\n",
    "\n",
    "    for l in range(L):\n",
    "        update[\"update_w\" + str(l+1)] = gamma*update[\"update_w\" + str(l+1)] + learning_rate*grads[\"dL_dw\" + str(l + 1)]\n",
    "        update[\"update_b\" + str(l+1)] = gamma*update[\"update_b\" + str(l+1)] + learning_rate*grads[\"dL_db\" + str(l + 1)]\n",
    "        \n",
    "        parameters[\"w\" + str(l+1)] = parameters[\"w\" + str(l+1)]-update[\"update_w\" + str(l+1)]\n",
    "        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)]- update[\"update_b\" + str(l+1)]\n",
    "\n",
    "    return parameters, update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_lookahead_parameters(parameters,update,gamma):\n",
    "    L = len(parameters) // 2 # number of layers in the neural network\n",
    "    lookahead_parameters = {}\n",
    "\n",
    "    for l in range(L):\n",
    "        lookahead_parameters[\"w\" + str(l+1)] = parameters[\"w\" + str(l+1)]-gamma*update[\"update_w\" + str(l+1)] \n",
    "        lookahead_parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)]-gamma*update[\"update_b\" + str(l+1)]\n",
    "    return lookahead_parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "iDKqDY1dLBoD"
   },
   "outputs": [],
   "source": [
    "def predict(x, y, parameters):\n",
    "    x =x.T\n",
    "    y =y.T\n",
    "    \n",
    "    m = x.shape[1]\n",
    "    n = len(parameters) // 2 # number of layers in the neural network\n",
    "    p = np.zeros((1,m))\n",
    "    \n",
    "    # Forward propagation\n",
    "    prob, temps = forward_pass(x, parameters)\n",
    "    \n",
    "\n",
    "    predicted_label = np.argmax(prob, axis=0)\n",
    "    true_label = np.argmax(y, axis=0)\n",
    "    \n",
    "    Accuracy = np.sum(predicted_label == true_label)/m\n",
    "        \n",
    "#         if probas[0,i] > 0.5:\n",
    "#             p[0,i] = 1\n",
    "#         else:\n",
    "#             p[0,i] = 0\n",
    "    \n",
    "    #print results\n",
    "    #print (\"predictions: \" + str(p))\n",
    "    #print (\"true labels: \" + str(y))\n",
    "    print(\"Accuracy: \"  + str(Accuracy))\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RK_ze5mDLBoD",
    "outputId": "c7e09113-b4de-4448-d25c-92df6bdcdd7c"
   },
   "source": [
    "x_train_orig = x_train_orig[:10]\n",
    "x_test_orig = x_test_orig[:5]\n",
    "y_train_orig = y_train_orig[:10]\n",
    "y_test_orig = y_train_orig[:5]\n",
    "y_train_orig.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9vqejUVSLBoE",
    "outputId": "7198b220-8fdd-4216-c443-326e179f4330"
   },
   "source": [
    "x_train_flatten = x_train_orig.reshape(x_train_orig.shape[0], -1)#.T\n",
    "x_test_flatten = x_test_orig.reshape(x_test_orig.shape[0], -1)#.T\n",
    "x_train = x_train_flatten/255\n",
    "x_test = x_test_flatten/255\n",
    "\n",
    "print (\"x_train's shape: \" + str(x_train.shape))\n",
    "print (\"x_test's shape: \" + str(x_test.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "MSTq1e4SLBoE"
   },
   "outputs": [],
   "source": [
    "# index = 15\n",
    "# plt.imshow(x_train_orig[index])\n",
    "# print (\"y = \" + str(y_train_orig[index])+ \". It's a \" + class_names[y_train_orig[index]] +  \" picture.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = np.array([[1,2,3,4],[3,4,5,6],[5,6,7,8]])\n",
    "y_train = np.array([[0,0,1],[1,0,0],[0,1,0]])\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "SwhPEvKjLBoF"
   },
   "outputs": [],
   "source": [
    "no_hidden_layers = 1 # no of hidden layers\n",
    "no_neuron_hidden = 4 # no. of neurons in each hidden layers\n",
    "no_neuron_output = 3 # # no. of neurons in each hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "WVOCfRCQLBoG"
   },
   "outputs": [],
   "source": [
    "no_of_training_examples = np.shape(x_train)[0]\n",
    "#no_of_testing_examples = np.shape(x_test)[0]\n",
    "size_input_layer = np.shape(x_train)[1]\n",
    "size_hidden_layer = no_neuron_hidden\n",
    "size_output_layer = no_neuron_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "OjczHGgOLBoG"
   },
   "outputs": [],
   "source": [
    "def one_hot_vector_form(labels,size_output_layer):\n",
    "    no_of_examples = labels.shape[0]\n",
    "    one_hot_vector = np.zeros((no_of_examples , size_output_layer))\n",
    "    for i in range(no_of_examples):\n",
    "        one_hot_vector[i, labels[i]] = 1    \n",
    "        y = one_hot_vector#.T\n",
    "    return y  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VkU692HSLBoG",
    "outputId": "8db703a3-d2ba-46ec-ce95-07d531c7909d"
   },
   "source": [
    "y_train = one_hot_vector_form(y_train_orig,size_output_layer)\n",
    "y_test = one_hot_vector_form(y_test_orig,size_output_layer)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "Uy66Fnq-NBMK"
   },
   "source": [
    "num_steps = 4\n",
    "batchsize = 2\n",
    "for j in range(num_steps):\n",
    "  start = j*batchsize\n",
    "  end = start+batchsize\n",
    "  x = x_train[start:end].T\n",
    "  y = y_train[start:end].T \n",
    "            \n",
    "  #print(\"x\",x)\n",
    "  #print(\"Y\",y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RNHTywuvLBoH",
    "outputId": "2c44494e-bce9-45f2-ee3d-658f8acae3af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 4, 3]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_dimensions = [size_input_layer]+ [size_hidden_layer]*no_hidden_layers+ [size_output_layer]\n",
    "layer_dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'w1': array([[-0.71586379, -0.60550807,  0.65897813, -1.42415746],\n",
       "        [-0.57116409, -0.69220739, -1.10277752,  0.86515635],\n",
       "        [-1.30960855, -0.998372  , -0.02451508, -1.85132059],\n",
       "        [-0.62809248,  0.10892502, -0.62449993, -0.05636695]]),\n",
       " 'b1': array([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]]),\n",
       " 'w2': array([[-1.14414468, -1.57157571, -0.59874191,  0.32573063],\n",
       "        [-0.71490638,  0.65037816, -1.09429188, -2.7186347 ],\n",
       "        [ 0.84925068,  0.02444377,  0.24658797, -0.01504266]]),\n",
       " 'b2': array([[0.],\n",
       "        [0.],\n",
       "        [0.]])}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = initialize_parameters(layer_dimensions)\n",
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.30112577, 0.33262299, 0.33341211],\n",
       "        [0.32843672, 0.33121876, 0.33303481],\n",
       "        [0.37043751, 0.33615825, 0.33355308]]),\n",
       " [((array([[1, 3, 5],\n",
       "           [2, 4, 6],\n",
       "           [3, 5, 7],\n",
       "           [4, 6, 8]]),\n",
       "    array([[-0.71586379, -0.60550807,  0.65897813, -1.42415746],\n",
       "           [-0.57116409, -0.69220739, -1.10277752,  0.86515635],\n",
       "           [-1.30960855, -0.998372  , -0.02451508, -1.85132059],\n",
       "           [-0.62809248,  0.10892502, -0.62449993, -0.05636695]]),\n",
       "    array([[0.],\n",
       "           [0.],\n",
       "           [0.],\n",
       "           [0.]])),\n",
       "   array([[ -5.64657539,  -9.81967777, -13.99278015],\n",
       "          [ -1.80328605,  -4.80527136,  -7.80725667],\n",
       "          [-10.78518015, -19.15281258, -27.52044501],\n",
       "          [ -2.50921005,  -4.90927873,  -7.30934741]])),\n",
       "  ((array([[3.51716941e-03, 5.43681452e-05, 8.37553252e-07],\n",
       "           [1.41451527e-01, 8.12000500e-03, 4.06607034e-04],\n",
       "           [2.07036436e-05, 4.80882732e-09, 1.11692135e-12],\n",
       "           [7.52150384e-02, 7.32377443e-03, 6.68806058e-04]]),\n",
       "    array([[-1.14414468, -1.57157571, -0.59874191,  0.32573063],\n",
       "           [-0.71490638,  0.65037816, -1.09429188, -2.7186347 ],\n",
       "           [ 0.84925068,  0.02444377,  0.24658797, -0.01504266]]),\n",
       "    array([[0.],\n",
       "           [0.],\n",
       "           [0.]])),\n",
       "   array([[-2.01838490e-01, -1.04378329e-02, -4.22121404e-04],\n",
       "          [-1.15022332e-01, -1.46684668e-02, -1.55438980e-03],\n",
       "          [ 5.31823788e-03,  1.34487833e-04,  5.89677572e-07]]))])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward_pass(x_train.T, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "predict(x_train, y_train, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "tFIBmzk1LBoH"
   },
   "outputs": [],
   "source": [
    "def L_layer_network(x_train, y_train,layer_dimensions,learning_rate,gamma, num_epochs,batch_type,batchsize,\n",
    "                   grad_deescent_type,print_cost=False):\n",
    "    \n",
    "\n",
    "    #np.random.seed(1)\n",
    "    costs = []          \n",
    "    \n",
    "    parameters = initialize_parameters(layer_dimensions)\n",
    "    update = initialize_update(layer_dimensions)\n",
    "    if batch_type == \"SGD\":\n",
    "        batchsize =1\n",
    "    elif batch_type ==  \"Mini_batch\":\n",
    "        batchsize = batchsize\n",
    "    elif batch_type == \"Full_batch\":\n",
    "        batchsize = x_train.shape[0]\n",
    "        \n",
    "    total_examples = x_train.shape[0]\n",
    "    num_steps = total_examples//batchsize\n",
    "    #print(num_steps)\n",
    " \n",
    "    for i in range(0, num_epochs):\n",
    "        print(\"***********epoch = \",i)\n",
    "        par_update = 0\n",
    "        for j in range(num_steps):\n",
    "            \n",
    "            start = j*batchsize\n",
    "            end = start+batchsize\n",
    "            x = x_train[start:end].T\n",
    "            y = y_train[start:end].T \n",
    "            \n",
    "            #print(\"param\",parameters)\n",
    "            #print(\"in update\",update)\n",
    "               \n",
    "            if grad_deescent_type == \"Vanilla\":\n",
    "            \n",
    "                yhat, temps = forward_pass(x, parameters)\n",
    "                cost = cost_function(yhat, y)\n",
    "                grads = backward_pass(yhat,y,temps)\n",
    "                parameters = parameter_update_vanilla(parameters, grads,learning_rate)\n",
    "                \n",
    "            elif grad_deescent_type == \"Momentum\":\n",
    "                \n",
    "                yhat, temps = forward_pass(x, parameters)\n",
    "                cost = cost_function(yhat, y)\n",
    "                grads = backward_pass(yhat,y,temps)\n",
    "                #print(\"in update\",update)\n",
    "                parameters,update = parameter_update_momentum(parameters, grads, update, learning_rate ,gamma)\n",
    "                #print(\"out update\",update)\n",
    "                \n",
    "            elif grad_deescent_type == \"NAG\":\n",
    "                lookahead_parameters = find_lookahead_parameters(parameters,update,gamma)\n",
    "                #print(\"lookahead_parameters\",lookahead_parameters)\n",
    "                yhat, temps = forward_pass(x, lookahead_parameters)\n",
    "                cost = cost_function(yhat, y)\n",
    "                grads = backward_pass(yhat,y,temps)\n",
    "                parameters,update = parameter_update_momentum(parameters, grads, update, learning_rate ,gamma)\n",
    "\n",
    "            #print(\"out update\",update)\n",
    "            par_update += 1\n",
    "        \n",
    "        print(\"par_updated \",par_update,\"times\")\n",
    "        print(\"***********************************************************\")\n",
    "        \n",
    "    #     #print(\"cost in iteration \",i,\" is =\",cost)\n",
    "                \n",
    "    #         # Print the cost every 100 training example\n",
    "    #     if print_cost and i % 100 == 0:\n",
    "    #         print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "    #     if print_cost and i % 100 == 0:\n",
    "    #         costs.append(cost)\n",
    "    # # plot the cost\n",
    "    # plt.plot(np.squeeze(costs))\n",
    "    # plt.ylabel('cost')\n",
    "    # plt.xlabel('iterations (per hundreds)')\n",
    "    # plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    # plt.show()\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S4gK1XfLLBoI",
    "outputId": "aaf77a51-a907-4e68-e1b3-5d3793c1400f",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********epoch =  0\n",
      "par_updated  1 times\n",
      "***********************************************************\n",
      "***********epoch =  1\n",
      "par_updated  1 times\n",
      "***********************************************************\n"
     ]
    }
   ],
   "source": [
    "parameters = L_layer_network(x_train, y_train, layer_dimensions,1,0.9,2,\"Full_batch\",1,\"Vanilla\",print_cost = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'w1': array([[-0.35019555,  1.30889103,  2.03061962, -1.86649547],\n",
       "        [-0.67394888,  1.87991259,  0.54175514,  0.33039636],\n",
       "        [-1.98065672,  0.22936762, -0.47406352,  0.12342723],\n",
       "        [-0.3406421 ,  0.7907601 , -0.13481437,  1.38529023]]),\n",
       " 'b1': array([[-0.04934173],\n",
       "        [ 0.00039241],\n",
       "        [-0.04825434],\n",
       "        [ 0.00064664]]),\n",
       " 'w2': array([[ 1.76852794, -0.22563902, -0.71350865, -0.6106242 ],\n",
       "        [-0.11719976, -0.19370735,  0.60045324,  1.26370635],\n",
       "        [-0.96149393,  0.3784562 ,  1.14029767,  1.74207237]]),\n",
       " 'b2': array([[ 0.09514906],\n",
       "        [ 0.07195659],\n",
       "        [-0.16710565]])}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "6ZaDOFXELBoI",
    "outputId": "f4dd0bb2-b713-474c-d4b2-e449417426cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "predict(x_train, y_train, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.18356911, 0.31510608, 0.33508608],\n",
       "        [0.35547496, 0.34166959, 0.337239  ],\n",
       "        [0.46095593, 0.34322432, 0.32767491]]),\n",
       " [((array([[1, 3, 5],\n",
       "           [2, 4, 6],\n",
       "           [3, 5, 7],\n",
       "           [4, 6, 8]]),\n",
       "    array([[-0.35019555,  1.30889103,  2.03061962, -1.86649547],\n",
       "           [-0.67394888,  1.87991259,  0.54175514,  0.33039636],\n",
       "           [-1.98065672,  0.22936762, -0.47406352,  0.12342723],\n",
       "           [-0.3406421 ,  0.7907601 , -0.13481437,  1.38529023]]),\n",
       "    array([[-0.04934173],\n",
       "           [ 0.00039241],\n",
       "           [-0.04825434],\n",
       "           [ 0.00064664]])),\n",
       "   array([[  0.84412176,   3.08976102,   5.33540028],\n",
       "          [  6.03311956,  10.18934998,  14.34558039],\n",
       "          [ -2.49865747,  -6.70250826, -10.90635905],\n",
       "          [  6.37824256,   9.77943027,  13.18061799]])),\n",
       "  ((array([[6.99332595e-01, 9.56468416e-01, 9.95205120e-01],\n",
       "           [9.97607735e-01, 9.99962433e-01, 9.99999411e-01],\n",
       "           [7.59523497e-02, 1.22632261e-03, 1.83408932e-05],\n",
       "           [9.98304774e-01, 9.99943399e-01, 9.99998113e-01]]),\n",
       "    array([[ 1.76852794, -0.22563902, -0.71350865, -0.6106242 ],\n",
       "           [-0.11719976, -0.19370735,  0.60045324,  1.26370635],\n",
       "           [-0.96149393,  0.3784562 ,  1.14029767,  1.74207237]]),\n",
       "    array([[ 0.09514906],\n",
       "           [ 0.07195659],\n",
       "           [-0.16710565]])),\n",
       "   array([[0.44305736, 0.94959501, 1.01892211],\n",
       "          [1.10392094, 1.03052981, 1.02532652],\n",
       "          [1.36376858, 1.03506989, 0.99655664]]))])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward_pass(x_train.T, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tg0V3J9RLBoJ",
    "outputId": "3ec70517-246f-4afb-df38-6a503a21c787"
   },
   "outputs": [],
   "source": [
    "predict(x_test,y_test,parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GopICBHzLBoJ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Q3A1_final_1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
