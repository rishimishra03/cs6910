{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "35I0Rq_ALBn1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import fashion_mnist\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "95tMwn2GLBn-"
   },
   "outputs": [],
   "source": [
    "def sigmoid(a):\n",
    "    s = 1/(1+np.exp(-a))\n",
    "    return s\n",
    "\n",
    "def derivative_sigmoid(a):\n",
    "    ds = sigmoid(a) *(1-sigmoid (a))\n",
    "    return ds\n",
    "\n",
    "def tanh(a):\n",
    "    t=(np.exp(a)-np.exp(-a))/(np.exp(a)+np.exp(-a))\n",
    "    return t\n",
    "\n",
    "def derivative_tanh(a):\n",
    "    dt=1-tanh(a)**2\n",
    "    return dt\n",
    "\n",
    "\n",
    "def softmax(a):\n",
    "    return np.exp(a) / np.sum(np.exp(a), axis=0) #expA (axis=0, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "jPo8y7emLBn_"
   },
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yaktHRmbLBn_",
    "outputId": "d34bec94-2a04-4235-81ff-4f96c7c87ead"
   },
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(x_train_orig, y_train_orig), (x_test_orig, y_test_orig) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Pgc8UpKtLBn_"
   },
   "outputs": [],
   "source": [
    "def initialize_parameters(layer_dimensions):\n",
    "\n",
    "    #np.random.seed(0)\n",
    "    parameters = {}\n",
    "    L = len(layer_dimensions)            # number of layers in the network\n",
    "\n",
    "    for k in range(1, L):\n",
    "        \n",
    "        parameters['w' + str(k)] = np.random.randn(layer_dimensions[k], layer_dimensions[k-1]) \n",
    "        parameters['b' + str(k)] = np.zeros((layer_dimensions[k], 1))\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "44uvQtw7LBoA"
   },
   "outputs": [],
   "source": [
    "def agrregation_forward(h, w, b):\n",
    "    \n",
    "    a = np.dot(w, h) + b\n",
    "    temp = (h,w,b)\n",
    "    \n",
    "    return a ,temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ynL63aRULBoA"
   },
   "outputs": [],
   "source": [
    "def activation_forward(h_prev, w, b, activation):\n",
    "        \n",
    "    \n",
    "    if activation == \"sigmoid\":\n",
    "\n",
    "        a, linear_temp = agrregation_forward(h_prev, w, b)\n",
    "        h = sigmoid(a)\n",
    "    \n",
    "    elif activation == \"tanh\":\n",
    "        a, linear_temp = agrregation_forward(h_prev, w, b)\n",
    "        h = tanh(a)\n",
    "        \n",
    "    elif activation == \"softmax\":\n",
    "        a, linear_temp = agrregation_forward(h_prev, w, b)\n",
    "        h = softmax(a)\n",
    "    \n",
    "    \n",
    "    temp = (linear_temp, a)\n",
    "\n",
    "    return h, temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "d7MK5JmxLBoB"
   },
   "outputs": [],
   "source": [
    "def forward_pass(x, parameters):\n",
    "\n",
    "    temps = []\n",
    "    h = x\n",
    "    L = len(parameters) // 2                  # number of layers in the neural network\n",
    "    \n",
    "    for k in range(L-1):\n",
    "        l = k+1\n",
    "        h_prev = h \n",
    "        h,temp = activation_forward(h_prev, parameters['w'+str(l)], parameters['b'+str(l)], activation=\"sigmoid\")\n",
    "        temps.append(temp)\n",
    "    \n",
    "    \n",
    "    hL,temp1 = activation_forward(h, parameters['w'+str(L)], parameters['b'+str(L)], activation=\"softmax\")\n",
    "    temps.append(temp1)\n",
    "    \n",
    "            \n",
    "    return hL, temps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "OX6qxo5yLBoB"
   },
   "outputs": [],
   "source": [
    "def cost_function(yhat, y):   \n",
    "    m = y.shape[1] # no. of examples\n",
    "  \n",
    "    product_sum = np.sum((y *np.log(yhat)), axis = 0)\n",
    "    cost = -1/m*np.sum(product_sum)\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "4sEmnKQzLBoB"
   },
   "outputs": [],
   "source": [
    "def agrregation_backward(dL_da, temp):\n",
    "    \n",
    "    h_prev, w, b = temp \n",
    "    m = h_prev.shape[1]\n",
    "    dL_dh_prev = np.dot(w.T, dL_da)\n",
    "    \n",
    "    dL_dw = 1/m*np.dot(dL_da, h_prev.T)\n",
    "    dL_db = 1/m*np.sum(dL_da, axis=1, keepdims=True)\n",
    "     \n",
    "\n",
    "    return dL_dh_prev, dL_dw, dL_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "k5_8wzplLBoC"
   },
   "outputs": [],
   "source": [
    "def activation_backward(dL_dh, temp, activation):\n",
    "\n",
    "    linear_temp, a = temp\n",
    "    \n",
    "    if activation == \"sigmoid\":\n",
    "        ds = derivative_sigmoid(a)\n",
    "        dL_da = dL_dh * ds\n",
    "       \n",
    "        dL_dh_prev, dL_dw, dL_db = agrregation_backward(dL_da, linear_temp)    \n",
    "        \n",
    "    elif activation == \"tanh\":\n",
    "        dt = derivative_tanh(a)\n",
    "        dL_da = dL_dh * dt\n",
    "\n",
    "        dL_dh_prev, dL_dw, dL_db = agrregation_backward(dL_da, linear_temp)    \n",
    "    \n",
    "    return dL_dh_prev, dL_dw, dL_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Izs4-_QvLBoC"
   },
   "outputs": [],
   "source": [
    "def backward_pass(yhat, y, temps):\n",
    "    \n",
    "    grads = {}\n",
    "    L = len(temps) # the number of layers\n",
    "    m = y.shape[1]\n",
    "\n",
    "# el = one hot vector\n",
    "    el = y\n",
    "    dL_dyhat = -(1/yhat)*el\n",
    "    dL_daL  = -(el - yhat)\n",
    "    current_temp = temps[L-1]\n",
    "    linear_tempL,aL = current_temp\n",
    "    \n",
    "    hL_prev, wL, bL = linear_tempL\n",
    "    m = hL_prev.shape[1]\n",
    "\n",
    "    dL_dhL_prev = np.dot(wL.T, dL_daL)\n",
    "    \n",
    "    dL_dwL = 1/m*np.dot(dL_daL, hL_prev.T)\n",
    "    dL_dbL = 1/m*np.sum(dL_daL, axis=1, keepdims=True)\n",
    "\n",
    "    \n",
    "    grads[\"dL_dh\" + str(L-1)] = dL_dhL_prev\n",
    "    grads[\"dL_dw\" + str(L)]      = dL_dwL\n",
    "    grads[\"dL_db\" + str(L)] = dL_dbL\n",
    "    \n",
    "    # Loop from l=L-2 to l=0\n",
    "    for l in reversed(range(L-1)):\n",
    "        #print(l)\n",
    "        current_temp = temps[l]\n",
    "        dL_dh_prev, dL_dw, dL_db = activation_backward(grads[\"dL_dh\" + str(l+1)], current_temp, \"sigmoid\")\n",
    "        grads[\"dL_dh\" + str(l)] = dL_dh_prev\n",
    "        grads[\"dL_dw\" + str(l + 1)] = dL_dw\n",
    "        grads[\"dL_db\" + str(l + 1)] = dL_db\n",
    "\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "SzwkIK5CLBoD"
   },
   "outputs": [],
   "source": [
    "def parameter_update(parameters, grads, learning_rate):\n",
    "    \n",
    "    L = len(parameters) // 2 # number of layers in the neural network\n",
    "\n",
    "    for l in range(L):\n",
    "        parameters[\"w\" + str(l+1)] = parameters[\"w\" + str(l+1)]-learning_rate*grads[\"dL_dw\" + str(l + 1)]\n",
    "        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)]-learning_rate*grads[\"dL_db\" + str(l + 1)]\n",
    "\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameter_update(parameters, grads, learning_rate):\n",
    "    \n",
    "    L = len(parameters) // 2 # number of layers in the neural network\n",
    "\n",
    "    for l in range(L):\n",
    "        parameters[\"w\" + str(l+1)] = parameters[\"w\" + str(l+1)]-learning_rate*grads[\"dL_dw\" + str(l + 1)]\n",
    "        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)]-learning_rate*grads[\"dL_db\" + str(l + 1)]\n",
    "\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "iDKqDY1dLBoD"
   },
   "outputs": [],
   "source": [
    "def predict(x, y, parameters):\n",
    "    x =x.T\n",
    "    y =y.T\n",
    "    \n",
    "    m = x.shape[1]\n",
    "    n = len(parameters) // 2 # number of layers in the neural network\n",
    "    p = np.zeros((1,m))\n",
    "    \n",
    "    # Forward propagation\n",
    "    prob, temps = forward_pass(x, parameters)\n",
    "    \n",
    "\n",
    "    predicted_label = np.argmax(prob, axis=0)\n",
    "    true_label = np.argmax(y, axis=0)\n",
    "    \n",
    "    Accuracy = np.sum(predicted_label == true_label)/m\n",
    "        \n",
    "#         if probas[0,i] > 0.5:\n",
    "#             p[0,i] = 1\n",
    "#         else:\n",
    "#             p[0,i] = 0\n",
    "    \n",
    "    #print results\n",
    "    #print (\"predictions: \" + str(p))\n",
    "    #print (\"true labels: \" + str(y))\n",
    "    print(\"Accuracy: \"  + str(Accuracy))\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RK_ze5mDLBoD",
    "outputId": "c7e09113-b4de-4448-d25c-92df6bdcdd7c"
   },
   "source": [
    "x_train_orig = x_train_orig[:10]\n",
    "x_test_orig = x_test_orig[:5]\n",
    "y_train_orig = y_train_orig[:10]\n",
    "y_test_orig = y_train_orig[:5]\n",
    "y_train_orig.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9vqejUVSLBoE",
    "outputId": "7198b220-8fdd-4216-c443-326e179f4330"
   },
   "source": [
    "x_train_flatten = x_train_orig.reshape(x_train_orig.shape[0], -1)#.T\n",
    "x_test_flatten = x_test_orig.reshape(x_test_orig.shape[0], -1)#.T\n",
    "x_train = x_train_flatten/255\n",
    "x_test = x_test_flatten/255\n",
    "\n",
    "print (\"x_train's shape: \" + str(x_train.shape))\n",
    "print (\"x_test's shape: \" + str(x_test.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "id": "MSTq1e4SLBoE"
   },
   "outputs": [],
   "source": [
    "# index = 15\n",
    "# plt.imshow(x_train_orig[index])\n",
    "# print (\"y = \" + str(y_train_orig[index])+ \". It's a \" + class_names[y_train_orig[index]] +  \" picture.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = np.array([[1,2,3,4],[3,4,5,6],[5,6,7,8]])\n",
    "y_train = np.array([[0,0,1],[1,0,0],[0,1,0]])\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "id": "SwhPEvKjLBoF"
   },
   "outputs": [],
   "source": [
    "no_hidden_layers = 1 # no of hidden layers\n",
    "no_neuron_hidden = 4 # no. of neurons in each hidden layers\n",
    "no_neuron_output = 3 # # no. of neurons in each hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "id": "WVOCfRCQLBoG"
   },
   "outputs": [],
   "source": [
    "no_of_training_examples = np.shape(x_train)[0]\n",
    "no_of_testing_examples = np.shape(x_test)[0]\n",
    "size_input_layer = np.shape(x_train)[1]\n",
    "size_hidden_layer = no_neuron_hidden\n",
    "size_output_layer = no_neuron_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "id": "OjczHGgOLBoG"
   },
   "outputs": [],
   "source": [
    "def one_hot_vector_form(labels,size_output_layer):\n",
    "    no_of_examples = labels.shape[0]\n",
    "    one_hot_vector = np.zeros((no_of_examples , size_output_layer))\n",
    "    for i in range(no_of_examples):\n",
    "        one_hot_vector[i, labels[i]] = 1    \n",
    "        y = one_hot_vector#.T\n",
    "    return y  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VkU692HSLBoG",
    "outputId": "8db703a3-d2ba-46ec-ce95-07d531c7909d"
   },
   "source": [
    "y_train = one_hot_vector_form(y_train_orig,size_output_layer)\n",
    "y_test = one_hot_vector_form(y_test_orig,size_output_layer)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "Uy66Fnq-NBMK"
   },
   "source": [
    "num_steps = 4\n",
    "batchsize = 2\n",
    "for j in range(num_steps):\n",
    "  start = j*batchsize\n",
    "  end = start+batchsize\n",
    "  x = x_train[start:end].T\n",
    "  y = y_train[start:end].T \n",
    "            \n",
    "  #print(\"x\",x)\n",
    "  #print(\"Y\",y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RNHTywuvLBoH",
    "outputId": "2c44494e-bce9-45f2-ee3d-658f8acae3af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 4, 3]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_dimensions = [size_input_layer]+ [size_hidden_layer]*no_hidden_layers+ [size_output_layer]\n",
    "layer_dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "id": "tFIBmzk1LBoH"
   },
   "outputs": [],
   "source": [
    "def L_layer_network(x_train, y_train,layer_dimensions,learning_rate,num_epochs,batchsize,batch_type,print_cost=False):\n",
    "    \n",
    "\n",
    "    np.random.seed(1)\n",
    "    costs = []          \n",
    "    \n",
    "    parameters = initialize_parameters(layer_dimensions)\n",
    "    if batch_type == \"SGD\":\n",
    "        batchsize =1\n",
    "    elif batch_type ==  \"Mini_batch\":\n",
    "        batchsize = batchsize\n",
    "    elif batch_type == \"Full_batch\":\n",
    "        batchsize = x_train.shape[0]\n",
    "        \n",
    "    total_examples = x_train.shape[0]\n",
    "    num_steps = total_examples//batchsize\n",
    "    #print(num_steps)\n",
    " \n",
    "    for i in range(0, num_epochs):\n",
    "        #print(\"***********epoch = \",i)\n",
    "        par_update = 0\n",
    "        for j in range(num_steps):\n",
    "            \n",
    "            start = j*batchsize\n",
    "            end = start+batchsize\n",
    "            x = x_train[start:end].T\n",
    "            y = y_train[start:end].T \n",
    "            \n",
    "            # print(\"x\",x)\n",
    "            # print(\"Y\",y)\n",
    "            \n",
    "            #print(\"::::::::::::::::::Input_param\",parameters)\n",
    "       \n",
    "            yhat, temps = forward_pass(x, parameters)\n",
    "            cost = cost_function(yhat, y)\n",
    "            grads = backward_pass(yhat,y,temps)\n",
    "            print(\"param\",grads)\n",
    "            parameters = parameter_update(parameters, grads, learning_rate)\n",
    "            #print(\"    update \",j+1)\n",
    "            print(\"param\",parameters)\n",
    "            par_update += 1\n",
    "        \n",
    "        #print(\"par_updated \",par_update,\"times\")\n",
    "        print(\"***********************************************************\")\n",
    "        \n",
    "    #     #print(\"cost in iteration \",i,\" is =\",cost)\n",
    "                \n",
    "    #         # Print the cost every 100 training example\n",
    "    #     if print_cost and i % 100 == 0:\n",
    "    #         print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "    #     if print_cost and i % 100 == 0:\n",
    "    #         costs.append(cost)\n",
    "    # # plot the cost\n",
    "    # plt.plot(np.squeeze(costs))\n",
    "    # plt.ylabel('cost')\n",
    "    # plt.xlabel('iterations (per hundreds)')\n",
    "    # plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    # plt.show()\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S4gK1XfLLBoI",
    "outputId": "aaf77a51-a907-4e68-e1b3-5d3793c1400f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param {'dL_dh1': array([[-1.18989369, -0.01633808,  0.95184263],\n",
      "       [ 0.73167716,  0.81599063, -1.25277271],\n",
      "       [ 0.49281199,  0.27042426, -0.6125784 ],\n",
      "       [ 1.08114124, -0.49791067, -0.44018795]]), 'dL_dw2': array([[ 0.00017078,  0.00333458,  0.00059602,  0.00491406],\n",
      "       [ 0.00067536,  0.02784868,  0.00280611,  0.01796557],\n",
      "       [-0.00084614, -0.03118326, -0.00340212, -0.02287962]]), 'dL_db2': array([[-0.01773531],\n",
      "       [ 0.05187744],\n",
      "       [-0.03414213]]), 'dL_dh0': array([[ 0.05205141,  0.05685563, -0.03386186],\n",
      "       [-0.28331533, -0.13158553,  0.09519219],\n",
      "       [ 0.31973125,  0.08916812, -0.07726712],\n",
      "       [-0.20919026, -0.03208832,  0.03727357]]), 'dL_dw1': array([[-0.00103781, -0.00256596, -0.0040941 , -0.00562225],\n",
      "       [ 0.02693163,  0.06846938,  0.11000713,  0.15154489],\n",
      "       [ 0.00227731,  0.00519836,  0.00811941,  0.01104046],\n",
      "       [ 0.01419887,  0.04329694,  0.07239502,  0.1014931 ]]), 'dL_db1': array([[-0.00152815],\n",
      "       [ 0.04153775],\n",
      "       [ 0.00292105],\n",
      "       [ 0.02909808]])}\n",
      "param {'w1': array([[ 1.62435315, -0.61173717, -0.52814105, -1.07292646],\n",
      "       [ 0.86520564, -2.30205222,  1.74398671, -0.76234349],\n",
      "       [ 0.31902202, -0.24940936,  1.46204704, -2.06022351],\n",
      "       [-0.3225237 , -0.38437908,  1.13322648, -1.10065247]]), 'b1': array([[ 1.14610942e-05],\n",
      "       [-3.11533142e-04],\n",
      "       [-2.19078840e-05],\n",
      "       [-2.18235575e-04]]), 'w2': array([[-0.17242949, -0.87788343,  0.04220928,  0.58277836],\n",
      "       [-1.10062424,  1.14451484,  0.90156967,  0.5023596 ],\n",
      "       [ 0.9008623 , -0.68349398, -0.12286471, -0.93559784]]), 'b2': array([[ 0.00013301],\n",
      "       [-0.00038908],\n",
      "       [ 0.00025607]])}\n",
      "***********************************************************\n",
      "param {'dL_dh1': array([[-1.18858786, -0.01533783,  0.95249728],\n",
      "       [ 0.72981809,  0.81477394, -1.2533795 ],\n",
      "       [ 0.4919831 ,  0.26981276, -0.61296142],\n",
      "       [ 1.08025055, -0.49840059, -0.44038545]]), 'dL_dw2': array([[ 0.0001714 ,  0.00340026,  0.00059863,  0.00492499],\n",
      "       [ 0.00067407,  0.02760975,  0.00279799,  0.01783582],\n",
      "       [-0.00084547, -0.03101001, -0.00339661, -0.02276081]]), 'dL_db2': array([[-0.01747366],\n",
      "       [ 0.05124382],\n",
      "       [-0.03377016]]), 'dL_dh0': array([[ 0.05145727,  0.05613273, -0.0332548 ],\n",
      "       [-0.28122115, -0.12985533,  0.09357108],\n",
      "       [ 0.31743762,  0.08788442, -0.07594944],\n",
      "       [-0.20809602, -0.03166421,  0.03673404]]), 'dL_dw1': array([[-0.00103436, -0.00256062, -0.00408687, -0.00561313],\n",
      "       [ 0.02704239,  0.06827008,  0.10949777,  0.15072547],\n",
      "       [ 0.00226723,  0.0051804 ,  0.00809358,  0.01100675],\n",
      "       [ 0.01420008,  0.04316609,  0.07213209,  0.10109809]]), 'dL_db1': array([[-0.00152625],\n",
      "       [ 0.04122769],\n",
      "       [ 0.00291317],\n",
      "       [ 0.028966  ]])}\n",
      "param {'w1': array([[ 1.6243609 , -0.61171796, -0.52811039, -1.07288436],\n",
      "       [ 0.86500282, -2.30256424,  1.74316548, -0.76347393],\n",
      "       [ 0.31900501, -0.24944822,  1.46198634, -2.06030606],\n",
      "       [-0.3226302 , -0.38470283,  1.13268549, -1.1014107 ]]), 'b1': array([[ 2.29080060e-05],\n",
      "       [-6.20740845e-04],\n",
      "       [-4.37566874e-05],\n",
      "       [-4.35480597e-04]]), 'w2': array([[-0.17243077, -0.87790893,  0.04220479,  0.58274142],\n",
      "       [-1.1006293 ,  1.14430777,  0.90154869,  0.50222583],\n",
      "       [ 0.90086864, -0.68326141, -0.12283923, -0.93542713]]), 'b2': array([[ 0.00026407],\n",
      "       [-0.00077341],\n",
      "       [ 0.00050934]])}\n",
      "***********************************************************\n"
     ]
    }
   ],
   "source": [
    "parameters = L_layer_network(x_train, y_train, layer_dimensions,0.0075,2,1,\"Full_batch\",print_cost = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "6ZaDOFXELBoI",
    "outputId": "f4dd0bb2-b713-474c-d4b2-e449417426cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3\n"
     ]
    }
   ],
   "source": [
    "predict(x_train,y_train,parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 784)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "Tg0V3J9RLBoJ",
    "outputId": "3ec70517-246f-4afb-df38-6a503a21c787"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2\n"
     ]
    }
   ],
   "source": [
    "predict(x_test,y_test,parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GopICBHzLBoJ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Q3A1_final_1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
